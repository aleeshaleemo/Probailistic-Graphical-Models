# -*- coding: utf-8 -*-
"""HMM_Customdataset

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tpNER2DfrkJU5keEG0Nv-3L6LQ_-GymB
"""

!pip install sklearn-crfsuite

# Custom dataset with 50 words and tags
custom_dataset = [
    [("Life", "NN"), ("is", "VBZ"), ("Beautiful", "JJ"), ("like", "IN"), ("a", "DT"), ("diamond", "NN"), (".", ".")],
    [("I", "PRP"), ("love", "VBP"), ("coding", "VBG"), (".", ".")],
    [("The", "DT"), ("quick", "JJ"), ("brown", "JJ"), ("fox", "NN"), ("jumps", "VBZ"), ("over", "IN"), ("the", "DT"), ("lazy", "JJ"), ("dog", "NN"), (".", ".")],
    [("Python", "NN"), ("is", "VBZ"), ("a", "DT"), ("popular", "JJ"), ("programming", "NN"), ("language", "NN"), (".", ".")],
    [("She", "PRP"), ("sells", "VBZ"), ("seashells", "NNS"), ("by", "IN"), ("the", "DT"), ("seashore", "NN"), (".", ".")],
    [("To", "TO"), ("be", "VB"), ("or", "CC"), ("not", "RB"), ("to", "TO"), ("be", "VB"), (",", ","), ("that", "DT"), ("is", "VBZ"), ("the", "DT"), ("question", "NN"), (".", ".")],
    [("All", "DT"), ("that", "DT"), ("glitters", "VBZ"), ("is", "VBZ"), ("not", "RB"), ("gold", "NN"), (".", ".")],
    [("Time", "NN"), ("flies", "VBZ"), ("like", "IN"), ("an", "DT"), ("arrow", "NN"), (".", ".")],
    [("I", "PRP"), ("have", "VBP"), ("a", "DT"), ("dream", "NN"), (".", ".")],
    [("The", "DT"), ("cat", "NN"), ("sat", "VBD"), ("on", "IN"), ("the", "DT"), ("mat", "NN"), (".", ".")],
    [("The", "DT"), ("moon", "NN"), ("is", "VBZ"), ("full", "JJ"), ("tonight", "NN"), (".", ".")],
    [("It", "PRP"), ("rains", "VBZ"), ("cats", "NNS"), ("and", "CC"), ("dogs", "NNS"), (".", ".")],
    [("Where", "WRB"), ("there", "EX"), ("is", "VBZ"), ("a", "DT"), ("will", "MD"), (",", ","), ("there", "EX"), ("is", "VBZ"), ("a", "DT"), ("way", "NN"), (".", ".")],
    [("Actions", "NNS"), ("speak", "VBP"), ("louder", "JJR"), ("than", "IN"), ("words", "NNS"), (".", ".")],
    [("The", "DT"), ("pen", "NN"), ("is", "VBZ"), ("mightier", "JJR"), ("than", "IN"), ("the", "DT"), ("sword", "NN"), (".", ".")],
    [("It", "PRP"), ("takes", "VBZ"), ("two", "CD"), ("to", "TO"), ("tango", "VB"), (".", ".")],
    [("Keep", "VB"), ("your", "PRP$"), ("friends", "NNS"), ("close", "RB"), ("and", "CC"), ("your", "PRP$"), ("enemies", "NNS"), ("closer", "JJR"), (".", ".")],
    [("Every", "DT"), ("cloud", "NN"), ("has", "VBZ"), ("a", "DT"), ("silver", "JJ"), ("lining", "NN"), (".", ".")],
    [("Don't", "NN"), ("count", "NN"), ("your", "PRP$"), ("chickens", "NNS"), ("before", "IN"), ("they", "PRP"), ("hatch", "VB"), (".", ".")],
    [("A", "DT"), ("bird", "NN"), ("in", "IN"), ("the", "DT"), ("hand", "NN"), ("is", "VBZ"), ("worth", "IN"), ("two", "CD"), ("in", "IN"), ("the", "DT"), ("bush", "NN"), (".", ".")],
    [("Don't", "NN"), ("put", "VB"), ("all", "DT"), ("your", "PRP$"), ("eggs", "NNS"), ("in", "IN"), ("one", "CD"), ("basket", "NN"), (".", ".")],
    [("A", "DT"), ("stitch", "NN"), ("in", "IN"), ("time", "NN"), ("saves", "VBZ"), ("nine", "CD"), (".", ".")],
    [("The", "DT"), ("early", "JJ"), ("bird", "NN"), ("catches", "VBZ"), ("the", "DT"), ("worm", "NN"), (".", ".")],
    [("Honesty", "NN"), ("is", "VBZ"), ("the", "DT"), ("best", "JJS"), ("policy", "NN"), (".", ".")],
    [("When", "WRB"), ("in", "IN"), ("Rome", "NNP"), (",", ","), ("do", "VB"), ("as", "IN"), ("the", "DT"), ("Romans", "NNS"), ("do", ".", ".")],
    [("Rome", "NNP"), ("was", "VBD"), ("not", "RB"), ("built", "VBN"), ("in", "IN"), ("a", "DT"), ("day", "NN"), (".", ".")],
    [("Necessity", "NN"), ("is", "VBZ"), ("the", "DT"), ("mother", "NN"), ("of", "IN"), ("invention", "NN"), (".", ".")],
    [("Two", "CD"), ("heads", "NNS"), ("are", "VBP"), ("better", "JJR"), ("than", "IN"), ("one", "CD"), (".", ".")],
    [("The", "DT"), ("proof", "NN"), ("of", "IN"), ("the", "DT"), ("pudding", "NN"), ("is", "VBZ"), ("in", "IN"), ("the", "DT"), ("eating", "NN"), (".", ".")],
    [("Practice", "NN"), ("makes", "VBZ"), ("perfect", "JJ"), (".", ".")],
    [("Where", "WRB"), ("there's", "EX"), ("smoke", "NN"), (",", ","), ("there's", "EX"), ("fire", "NN"), (".", ".")],
    [("Beauty", "NN"), ("is", "VBZ"), ("in", "IN"), ("the", "DT"), ("eye", "NN"), ("of", "IN"), ("the", "DT"), ("beholder", "NN"), (".", ".")],
    [("You", "PRP"), ("can't", "MD"), ("teach", "VB"), ("an", "DT"), ("old", "JJ"), ("dog", "NN"), ("new", "JJ"), ("tricks", "NNS"), (".", ".")],
    [("Too", "RB"), ("many", "JJ"), ("cooks", "NNS"), ("spoil", "VBP"), ("the", "DT"), ("broth", "NN"), (".", ".")],
    [("A", "DT"), ("watched", "VBN"), ("pot", "NN"), ("never", "RB"), ("boils", "VBZ"), (".", ".")],
    [("Curiosity", "NN"), ("killed", "VBD"), ("the", "DT"), ("cat", "NN"), (".", ".")],
    [("Don't", "NN"), ("cry", "VB"), ("over", "IN"), ("spilt", "VBN"), ("milk", "NN"), (".", ".")],
    [("Beggars", "NNS"), ("can't", "MD"), ("be", "VB"), ("choosers", "NNS"), (".", ".")],
    [("A", "DT"), ("rolling", "VBG"), ("stone", "NN"), ("gathers", "VBZ"), ("no", "DT"), ("moss", "NN"), (".", ".")],
    [("A", "DT"), ("journey", "NN"), ("of", "IN"), ("a", "DT"), ("thousand", "CD"), ("miles", "NNS"), ("begins", "VBZ"), ("with", "IN"), ("a", "DT"), ("single", "JJ"), ("step", "NN"), (".", ".")],
    [("When", "WRB"), ("the", "DT"), ("going", "VBG"), ("gets", "VBZ"), ("tough", "JJ"), (",", ","), ("the", "DT"), ("tough", "JJ"), ("get", "VB"), ("going", "VBG"), (".", ".")],
    [("There's", "EX"), ("no", "DT"), ("place", "NN"), ("like", "IN"), ("home", "NN"), (".", ".")],
    [("Better", "RBR"), ("late", "RB"), ("than", "IN"), ("never", "RB"), (".", ".")],
    [("All's", "NNP"), ("well", "NN"), ("that", "DT"), ("ends", "VBZ"), ("well", "NN"), (".", ".")],
    [("You", "PRP"), ("can", "MD"), ("lead", "VB"), ("a", "DT"), ("horse", "NN"), ("to", "TO"), ("water", "NN"), (",", ","), ("but", "CC"), ("you", "PRP"), ("can't", "MD"), ("make", "VB"), ("it", "PRP"), ("drink", "VB"), (".", ".")],
    [("A", "DT"), ("bird", "NN"), ("in", "IN"), ("hand", "NN"), ("is", "VBZ"), ("worth", "IN"), ("two", "CD"), ("in", "IN"), ("the", "DT"), ("bush", "NN"), (".", ".")],
    [("An", "DT"), ("apple", "NN"), ("a", "DT"), ("day", "NN"), ("keeps", "VBZ"), ("the", "DT"), ("doctor", "NN"), ("away", "RB"), (".", ".")],
    [("A", "DT"), ("stitch", "NN"), ("in", "IN"), ("time", "NN"), ("saves", "VBZ"), ("nine", "CD"), (".", ".")],
    [("Beauty", "NN"), ("is", "VBZ"), ("only", "RB"), ("skin", "NN"), ("deep", "JJ"), (".", ".")],
    [("Blood", "NN"), ("is", "VBZ"), ("thicker", "JJR"), ("than", "IN"), ("water", "NN"), (".", ".")],
    [("The", "DT"), ("early", "JJ"), ("bird", "NN"), ("catches", "VBZ"), ("the", "DT"), ("worm", "NN"), (".", ".")],
    [("A", "DT"), ("friend", "NN"), ("in", "IN"), ("need", "NN"), ("is", "VBZ"), ("a", "DT"), ("friend", "NN"), ("indeed", "RB"), (".", ".")],
    [("A", "DT"), ("house", "NN"), ("divided", "VBN"), ("against", "IN"), ("itself", "PRP"), ("cannot", "VB"), ("stand", "VB"), (".", ".")],
    [("Absence", "NN"), ("makes", "VBZ"), ("the", "DT"), ("heart", "NN"), ("grow", "VB"), ("fonder", "NN"), (".", ".")]
]

import sklearn_crfsuite
from sklearn_crfsuite import metrics

# Define a function to extract features for each word in a sentence
def word_features(sentence, i):
    word = sentence[i][0]
    features = {
        'word': word,
        'is_first': i == 0,  # if the word is the first word
        'is_last': i == len(sentence) - 1,  # if the word is the last word
        'is_capitalized': word[0].upper() == word[0],
        'is_all_caps': word.upper() == word,  # word is in uppercase
        'is_all_lower': word.lower() == word,  # word is in lowercase
        # prefix of the word
        'prefix-1': word[0],
        'prefix-2': word[:2],
        'prefix-3': word[:3],
        # suffix of the word
        'suffix-1': word[-1],
        'suffix-2': word[-2:],
        'suffix-3': word[-3:],
        # extracting previous word
        'prev_word': '' if i == 0 else sentence[i - 1][0],
        # extracting next word
        'next_word': '' if i == len(sentence) - 1 else sentence[i + 1][0],
        'has_hyphen': '-' in word,  # if word has hypen
        'is_numeric': word.isdigit(),  # if word is in numeric
        'capitals_inside': word[1:].lower() != word[1:]
    }
    return features

# Extract features for each sentence in the custom dataset
X = []
y = []
for sentence in custom_dataset:
    X_sentence = []
    y_sentence = []
    for i in range(len(sentence)):
        X_sentence.append(word_features(sentence, i))
        y_sentence.append(sentence[i][1])
    X.append(X_sentence)
    y.append(y_sentence)

# Split the data into training and testing sets
split = int(0.8 * len(X))
X_train = X[:split]
y_train = y[:split]
X_test = X[split:]
y_test = y[split:]

# Train a CRF model on the training data
crf = sklearn_crfsuite.CRF(
    algorithm='lbfgs',
    c1=0.1,
    c2=0.1,
    max_iterations=100,
    all_possible_transitions=True
)
crf.fit(X_train, y_train)

# Make predictions on the test data and evaluate the performance
y_pred = crf.predict(X_test)

print("Accuracy:", metrics.flat_accuracy_score(y_test, y_pred))

# Tag a new sentence
sentence = 'The quick brown fox jumps over the lazy dog.'.split()
features = [word_features(sentence, i) for i in range(len(sentence))]
tags = crf.predict([features])
print(list(zip(sentence, tags[0])))

"""# **HMM using Customdataset**"""

import numpy
import nltk
from nltk.tag import hmm
nltk.download('treebank')
nltk.download('punkt')
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Convert custom dataset to tagged sentences format
tagged_sentences = custom_dataset

# Normalize the state matrix, emission matrix, and initial matrix
stateMatrix = numpy.matrix([[0.7, 0.3], [0.5, 0.5]]) / numpy.linalg.norm(stateMatrix)
emissionMatrix = numpy.matrix([[0.6, 0.1, 0.3], [0.1, 0.7, 0.2]]) / numpy.linalg.norm(emissionMatrix)
initialMatrix = numpy.array([1, 0]) / numpy.linalg.norm(initialMatrix)

# Initialize HMM trainer
trainer = hmm.HiddenMarkovModelTrainer()

# Train HMM tagger on the custom dataset
tagger = trainer.train_supervised(tagged_sentences)

# Define a sample sentence
sample_sentence = 'The quick brown fox jumps over the lazy dog.'

# Tokenize the sample sentence
tokens = nltk.word_tokenize(sample_sentence)

# Tag the sample sentence
tagged_sentence = tagger.tag(tokens)

print(tagged_sentence)

# Evaluate accuracy on the testing set
test_tokens = [word for sent in test_sentences for word, tag in sent]
test_tags = [tag for sent in test_sentences for word, tag in sent]
predicted_tags = [tag for word, tag in tagger.tag(test_tokens)]

# Calculate accuracy
accuracy = accuracy_score(test_tags, predicted_tags)

print("Accuracy:", accuracy)